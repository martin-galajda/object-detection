{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martingalajda/School/DIPLOMA-THESIS/object-detection/venv/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "from models.yolov3_gpu_head.inference import restore_model\n",
    "\n",
    "\n",
    "restored_model = restore_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Shape_3:0' shape=(5,) dtype=int32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "yolo_head_1_shape = K.shape(restored_model.outputs[0])\n",
    "yolo_head_2_shape = K.shape(restored_model.outputs[1])\n",
    "yolo_head_3_shape = K.shape(restored_model.outputs[2])\n",
    "\n",
    "def get_yolo_cols_and_rows(yolo_out_shape):\n",
    "    return yolo_out_shape[1], yolo_out_shape[2]\n",
    "\n",
    "yolo_head_1_grid_cols, yolo_head_1_grid_cols = get_yolo_cols_and_rows(yolo_head_1_shape)\n",
    "yolo_head_2_grid_cols, yolo_head_2_grid_cols = get_yolo_cols_and_rows(yolo_head_2_shape)\n",
    "yolo_head_3_grid_cols, yolo_head_3_grid_cols = get_yolo_cols_and_rows(yolo_head_3_shape)\n",
    "\n",
    "K.shape(restored_model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "fake_img_tensor = K.arange(0, 255)\n",
    "\n",
    "fake_img_tensor = K.concatenate([fake_img_tensor, fake_img_tensor, fake_img_tensor], axis=0)\n",
    "fake_img_tensor = K.reshape(fake_img_tensor, [1, 255, 3])\n",
    "\n",
    "# fake_img_tesnor = K.backend.reshape(fake_img_tensor, [1, ])\n",
    "K.eval(K.shape(fake_img_tensor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "num_of_cols, num_of_rows = 19, 15\n",
    "test_tensor = K.arange(0, num_of_cols)\n",
    "\n",
    "test_tensor = K.reshape(test_tensor, [1, num_of_cols, 1, 1])\n",
    "test_tensor = K.tile(test_tensor, [1, num_of_rows, 1, 1])\n",
    "test_tensor = K.reshape(test_tensor, [1, num_of_rows, num_of_cols, 1])\n",
    "\n",
    "K.eval(K.shape(test_tensor / K.shape(test_tensor)[::-1]))\n",
    "K.eval(K.shape(test_tensor)[::])\n",
    "K.eval(test_tensor / K.shape(test_tensor)[::-1])\n",
    "K.eval(test_tensor / K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284, 177\n"
     ]
    }
   ],
   "source": [
    "from utils.image import load_pil_image_from_file\n",
    "from utils.preprocess_image import resize_and_letter_box\n",
    "import numpy as np\n",
    "\n",
    "PATH_TO_TEST_FILE = '../resources/horse.jpeg'\n",
    "\n",
    "orig_img_pil, img_np = load_pil_image_from_file(PATH_TO_TEST_FILE)\n",
    "print(f'{orig_img_pil.width}, {orig_img_pil.height}')\n",
    "img_np = resize_and_letter_box(img_np/255., target_width = 608, target_height = 608)\n",
    "img_np = np.expand_dims(img_np, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corrected_boxes(*, box_width, box_height, box_x, box_y, orig_image_shape, model_image_shape):\n",
    "    orig_image_w, orig_image_h = orig_image_shape\n",
    "    model_w, model_h = model_image_shape\n",
    "\n",
    "    if float(model_w / orig_image_w) < float(model_h / orig_image_h):\n",
    "        new_w = model_w\n",
    "        new_h = (orig_image_h * model_w) / orig_image_w\n",
    "    else:\n",
    "        new_h = model_h\n",
    "        new_w = (orig_image_w * model_h) / orig_image_h\n",
    "\n",
    "    box_x = (box_x - (((model_w - new_w)/2.0)/model_w)) / float(new_w/model_w)\n",
    "    box_y = (box_y - (((model_h - new_h)/2.0)/model_h)) / float(new_h/model_h)\n",
    "\n",
    "    box_width *= model_w/new_w\n",
    "    box_height *= model_h/new_h\n",
    "\n",
    "    left = (box_x - (box_width/2.)) * orig_image_w\n",
    "    right = (box_x + (box_width/2.)) * orig_image_w\n",
    "    top = (box_y - (box_height/2.)) * orig_image_h\n",
    "    bottom = (box_y + (box_height/2.)) * orig_image_h\n",
    "\n",
    "    output_box = [\n",
    "        max(int(left), 0),\n",
    "        max(int(top), 0),\n",
    "        min(int(right), orig_image_w),\n",
    "        min(int(bottom), orig_image_h)\n",
    "    ]\n",
    "\n",
    "    return output_box\n",
    "\n",
    "\n",
    "def keras_get_corrected_boxes(*, box_width, box_height, box_x, box_y, orig_image_shape, model_image_shape):\n",
    "    orig_image_w, orig_image_h = orig_image_shape[0], orig_image_shape[1]\n",
    "    model_w, model_h = model_image_shape[0], model_image_shape[1]\n",
    "\n",
    "    scale = K.min(K.concatenate([(model_w/orig_image_w), (model_h/orig_image_h)]))\n",
    "    w_without_padding = orig_image_w * scale\n",
    "    h_without_padding = orig_image_h * scale\n",
    "\n",
    "#     if float(model_w / orig_image_w) < float(model_h / orig_image_h):\n",
    "#         w_without_padding = model_w\n",
    "#         h_without_padding = (orig_image_h) * model_w / orig_image_w\n",
    "#     else:\n",
    "#         h_without_padding = model_h\n",
    "#         w_without_padding = (orig_image_w) * model_h / orig_image_h\n",
    "        \n",
    "    x_shift = (model_w - w_without_padding)/2.0/ model_w\n",
    "    y_shift = (model_h - h_without_padding)/2.0/ model_h\n",
    "\n",
    "    box_x = (box_x - x_shift) / (w_without_padding / model_w)\n",
    "    box_y = (box_y - y_shift) / (h_without_padding / model_h)\n",
    "\n",
    "    box_width *= model_w/w_without_padding\n",
    "    box_height *= model_h/h_without_padding\n",
    "\n",
    "    left = (box_x - (box_width/2.))  * orig_image_w\n",
    "    right = (box_x + (box_width/2.))  * orig_image_w\n",
    "    top = (box_y - (box_height/2.))  * orig_image_h\n",
    "    bottom = (box_y + (box_height/2.))  * orig_image_h\n",
    "\n",
    "    output_boxes = K.concatenate([\n",
    "        K.reshape(left, [-1, 1]),\n",
    "        K.reshape(top, [-1, 1]),\n",
    "        K.reshape(right, [-1, 1]),\n",
    "        K.reshape(bottom, [-1, 1])\n",
    "    ])\n",
    "\n",
    "    return output_boxes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 30.346962213516235 seconds to construct network.\n",
      "Took 27.88591504096985 seconds\n",
      "np.array(all_curr_detected_objects) = [[ 34.637608  10.438645 279.33963  174.30429 ]]\n",
      "np.array(all_curr_detected_classes) = [0.9730875]\n",
      "np.array(all_curr_detected_scores) = [560]\n",
      "0.9730875\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from utils.non_max_suppression import non_max_suppression_fast, classic_non_max_suppression\n",
    "from models.utils.visualize import draw_detected_boxes_on_pil_image_v2\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "sess = K.get_session()\n",
    "\n",
    "NUM_OF_CLASSES = 601\n",
    "NUM_OF_ANCHORS = 3\n",
    "NUM_OF_BOX_PARAMS = 5\n",
    "ANCHORS = np.array([\n",
    "    [[116, 90], [156, 198], [373, 326]],\n",
    "    [[30, 61], [62, 45], [59, 119]],\n",
    "    [[10, 13], [16, 30], [33, 23]]\n",
    "]) / np.array([608., 608.])\n",
    "\n",
    "reshaped_heads = []\n",
    "\n",
    "orig_image_width, orig_image_height =  orig_img_pil.width, orig_img_pil.height\n",
    "\n",
    "prob_obj = []\n",
    "prob_class = []\n",
    "prob_detected = []\n",
    "boxes = []\n",
    "\n",
    "def get_grid(rows, cols):\n",
    "    grid_x = K.arange(0, stop=cols)\n",
    "    grid_x = K.reshape(grid_x, [1, -1, 1, 1])\n",
    "    grid_x = K.tile(grid_x, [rows, 1, 1, 1])\n",
    "    \n",
    "    grid_y = K.arange(0, stop=rows)\n",
    "    grid_y = K.reshape(grid_y, [-1, 1, 1, 1])\n",
    "    grid_y = K.tile(grid_y, [1, cols, 1, 1])\n",
    "    \n",
    "    grid = K.concatenate([grid_x, grid_y])\n",
    "    \n",
    "    return grid\n",
    "\n",
    "placeholder_orig_image_width = K.placeholder(shape=(1,))\n",
    "placeholder_orig_image_height = K.placeholder(shape=(1,))\n",
    " \n",
    "for yolo_head_idx in range(len(restored_model.output)):\n",
    "    yolo_head = restored_model.output[yolo_head_idx]\n",
    "    yolo_head_shape = K.shape(yolo_head)\n",
    "    yolo_head_num_of_cols, yolo_head_num_of_rows = yolo_head_shape[2], yolo_head_shape[1]\n",
    "    \n",
    "    curr_yolo_head = K.reshape(yolo_head, [-1, yolo_head_num_of_cols, yolo_head_num_of_rows, NUM_OF_ANCHORS, NUM_OF_BOX_PARAMS+NUM_OF_CLASSES])\n",
    "    grid = K.cast(get_grid(yolo_head_shape[1], yolo_head_shape[2]), dtype=K.dtype(curr_yolo_head))\n",
    "    \n",
    "    curr_boxes_xy = (K.sigmoid(curr_yolo_head[..., :2]) + grid) / K.cast([yolo_head_num_of_cols, yolo_head_num_of_rows],  dtype=K.dtype(curr_yolo_head))\n",
    "    curr_boxes_wh = K.exp(curr_yolo_head[..., 2:4]) * ANCHORS[yolo_head_idx]\n",
    "    \n",
    "    curr_prob_obj = K.sigmoid(curr_yolo_head[..., 4:5])\n",
    "    curr_prob_class = K.sigmoid(curr_yolo_head[..., 5:])\n",
    "    \n",
    "    curr_prob_detected_class = curr_prob_obj * curr_prob_class\n",
    "\n",
    "    boxes.append(keras_get_corrected_boxes(\n",
    "        box_width=curr_boxes_wh[..., 0:1],\n",
    "        box_height=curr_boxes_wh[..., 1:2],\n",
    "        box_x=curr_boxes_xy[..., 0:1],\n",
    "        box_y=curr_boxes_xy[..., 1:2],\n",
    "        orig_image_shape=(placeholder_orig_image_width, placeholder_orig_image_height),\n",
    "        model_image_shape=(608, 608)\n",
    "    ))\n",
    "    \n",
    "    curr_prob_detected_class = K.reshape(curr_prob_detected_class, [-1, NUM_OF_CLASSES])\n",
    "    prob_class.append(curr_prob_detected_class)\n",
    "\n",
    "    \n",
    "prob_class = K.concatenate(prob_class, axis = 0)\n",
    "boxes = K.concatenate(boxes, axis=0)\n",
    "\n",
    "mask = prob_class >= 0.25\n",
    "max_boxes_tensor = K.constant(20, dtype='int32')\n",
    "\n",
    "boxes_ = []\n",
    "scores_ = []\n",
    "classes_ = []\n",
    "\n",
    "for c in range(NUM_OF_CLASSES):\n",
    "    # TODO: use keras backend instead of tf.\n",
    "    class_boxes = tf.boolean_mask(boxes, mask[:, c])\n",
    "    class_box_scores = tf.boolean_mask(prob_class[:, c], mask[:, c])\n",
    "    nms_index = tf.image.non_max_suppression(class_boxes, class_box_scores, max_boxes_tensor, iou_threshold=0.5)\n",
    "    \n",
    "    \n",
    "    class_boxes = K.gather(class_boxes, nms_index)\n",
    "    class_box_scores = K.gather(class_box_scores, nms_index)\n",
    "    classes = K.ones_like(class_box_scores, 'int32') * c\n",
    "    \n",
    "    boxes_.append(class_boxes)\n",
    "    scores_.append(class_box_scores)\n",
    "    classes_.append(classes)\n",
    "    \n",
    "boxes_ = K.concatenate(boxes_, axis=0)\n",
    "scores_ = K.concatenate(scores_, axis=0)\n",
    "classes_ = K.concatenate(classes_, axis=0)\n",
    "\n",
    "\n",
    "# out_tensors = [\n",
    "#     boxes,\n",
    "#     prob_class,\n",
    "# ]\n",
    "\n",
    "out_tensors = [\n",
    "    boxes_,\n",
    "    scores_,\n",
    "    classes_\n",
    "]\n",
    "\n",
    "\n",
    "print(f'Took {time.time() - start} seconds to construct network.')\n",
    "\n",
    "start = time.time()\n",
    "sess_out = sess.run(out_tensors, feed_dict={\n",
    "    restored_model.input: img_np,\n",
    "    placeholder_orig_image_width: [orig_image_width],\n",
    "    placeholder_orig_image_height: [orig_image_height],\n",
    "    K.learning_phase(): 0\n",
    "})\n",
    "boxes, scores, out_boxes_classes = sess_out\n",
    "\n",
    "    \n",
    "all_curr_detected_objects = boxes\n",
    "all_curr_detected_classes = scores\n",
    "all_curr_detected_scores = out_boxes_classes\n",
    "\n",
    "# for c in range(NUM_OF_CLASSES):\n",
    "#     curr_mask_detected = out_boxes_classes[..., c] > 0.5\n",
    "#     curr_probs_class = out_boxes_classes[curr_mask_detected, :][:, c]\n",
    "#     c_boxes = boxes[curr_mask_detected, :]\n",
    "    \n",
    "#     curr_detected_objects = []\n",
    "#     curr_detected_classes = []\n",
    "#     curr_detected_scores = []\n",
    "\n",
    "#     for idx in range(np.count_nonzero(curr_mask_detected)):\n",
    "#         box_class_prob = curr_probs_class[idx]\n",
    "\n",
    "#         curr_detected_objects += [c_boxes[idx]]\n",
    "#         curr_detected_classes += [c]\n",
    "#         curr_detected_scores += [box_class_prob]\n",
    "        \n",
    "#     if len(curr_detected_objects) > 0:\n",
    "#         print(f'np.array(curr_detected_objects) = {np.array(curr_detected_objects)}')\n",
    "\n",
    "#         chosen_box_indices = classic_non_max_suppression(curr_detected_objects, curr_detected_scores, 0.6)\n",
    "#         curr_detected_objects = [curr_detected_objects[i] for i in chosen_box_indices]\n",
    "#         curr_detected_classes = [curr_detected_classes[i] for i in chosen_box_indices]\n",
    "#         curr_detected_scores = [curr_detected_scores[i] for i in chosen_box_indices]\n",
    "        \n",
    "#         all_curr_detected_objects += curr_detected_objects\n",
    "#         all_curr_detected_classes += curr_detected_classes\n",
    "#         all_curr_detected_scores += curr_detected_scores\n",
    "\n",
    "\n",
    "#     print(np.array(out).shape)\n",
    "    \n",
    "print(f'Took {time.time() - start} seconds')\n",
    "print(f'np.array(all_curr_detected_objects) = {np.array(all_curr_detected_objects)}')\n",
    "print(f'np.array(all_curr_detected_classes) = {np.array(all_curr_detected_classes)}')\n",
    "print(f'np.array(all_curr_detected_scores) = {np.array(all_curr_detected_scores)}')\n",
    "\n",
    "draw_detected_boxes_on_pil_image_v2(all_curr_detected_objects, all_curr_detected_classes, np.array(all_curr_detected_scores), orig_img_pil)\n",
    "orig_img_pil.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-db8d047d975a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "K.backend.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19078947, 0.14802632],\n",
       "       [0.25657895, 0.32565789],\n",
       "       [0.61348684, 0.53618421]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANCHORS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.]], dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.eval(K.concatenate([\n",
    "    K.constant([[1], [1]]),\n",
    "    K.constant([[2], [2]])\n",
    "], axis = 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
