{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLOV3_RESOURCES_DIR = '../resources/yolov3'\n",
    "YOLOV3_WEIGHTS_FILE_PATH = f'{YOLOV3_RESOURCES_DIR}/yolov3-openimages.weights'\n",
    "YOLOV3_CFG_FILE_PATH = f'{YOLOV3_RESOURCES_DIR}/yolov3-openimages.cfg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import io\n",
    "from collections import defaultdict\n",
    "\n",
    "def unique_config_sections(config_file):\n",
    "    \"\"\"Convert all config sections to have unique names.\n",
    "\n",
    "    Adds unique suffixes to config sections for compability with configparser.\n",
    "    \"\"\"\n",
    "    section_counters = defaultdict(int)\n",
    "    output_stream = io.StringIO()\n",
    "    with open(config_file) as fin:\n",
    "        for line in fin:\n",
    "            if line.startswith('['):\n",
    "                section = line.strip().strip('[]')\n",
    "                _section = section + '_' + str(section_counters[section])\n",
    "                section_counters[section] += 1\n",
    "                line = line.replace(section, _section)\n",
    "            output_stream.write(line)\n",
    "    output_stream.seek(0)\n",
    "    return output_stream\n",
    "\n",
    "def parse_darknet_config(path_to_config_file):\n",
    "    unique_config_file = unique_config_sections(path_to_config_file)\n",
    "    cfg_parser = configparser.ConfigParser()\n",
    "    cfg_parser.read_file(unique_config_file)\n",
    "    \n",
    "    for section in cfg_parser.sections():\n",
    "        print('Parsing section {}'.format(section))\n",
    "        print(dict(cfg_parser[section]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_darknet_config(YOLOV3_CFG_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras import backend as K\n",
    "from keras.layers import (Conv2D, GlobalAveragePooling2D, Input, Lambda,\n",
    "                          MaxPooling2D, UpSampling2D, Add)\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.utils.vis_utils import plot_model as plot\n",
    "\n",
    "\n",
    "def darknet_yolov3_to_keras(config_path, weights_path, output_path, *, fully_convolutional, plot_model = False, path_to_graph_output = None):\n",
    "    output_root = os.path.splitext(output_path)[0]\n",
    "\n",
    "    # Load weights and config.\n",
    "    print('Loading weights.')\n",
    "    weights_file = open(weights_path, 'rb')\n",
    "    WEIGHTS_HEADER_SIZE = 20\n",
    "#     weights_header = np.ndarray(shape=(4, ), dtype='int32', buffer=weights_file.read(WEIGHTS_HEADER_SIZE))\n",
    "    \n",
    "    major = np.ndarray(shape=(1, ), dtype='int32', buffer=weights_file.read(4))\n",
    "    minor = np.ndarray(shape=(1, ), dtype='int32', buffer=weights_file.read(4))\n",
    "    revision = np.ndarray(shape=(1, ), dtype='int32', buffer=weights_file.read(4))\n",
    "    seen = np.ndarray(shape=(1, ), dtype='int32', buffer=weights_file.read(8))\n",
    "\n",
    "    print(f'Weights Header: major,minor,revision,seen={major},{minor},{revision},{seen}.')\n",
    "    # TODO: Check transpose flag when implementing fully connected layers.\n",
    "    # transpose = (weight_header[0] > 1000) or (weight_header[1] > 1000)\n",
    "\n",
    "    print('Parsing Darknet config.')\n",
    "    unique_config_file = unique_config_sections(config_path)\n",
    "    cfg_parser = configparser.ConfigParser()\n",
    "    cfg_parser.read_file(unique_config_file)\n",
    "\n",
    "    print('Creating Keras model.')\n",
    "    if fully_convolutional:\n",
    "        print('Fully convolutional.')\n",
    "        image_height, image_width = None, None\n",
    "    else:\n",
    "        image_height = int(cfg_parser['net_0']['height'])\n",
    "        image_width = int(cfg_parser['net_0']['width'])\n",
    "    prev_layer = Input(shape=(image_height, image_width, 3))\n",
    "    all_layers = [prev_layer]\n",
    "    yolo_heads = []\n",
    "\n",
    "    weight_decay = float(cfg_parser['net_0']['decay']) if 'net_0' in cfg_parser.sections() else 5e-4\n",
    "    count = 0\n",
    "    for section in cfg_parser.sections():\n",
    "        print('Parsing section {}'.format(section))\n",
    "        if section.startswith('convolutional'):\n",
    "            filters = int(cfg_parser[section]['filters'])\n",
    "            size = int(cfg_parser[section]['size'])\n",
    "            stride = int(cfg_parser[section]['stride'])\n",
    "            pad = int(cfg_parser[section]['pad'])\n",
    "            activation = cfg_parser[section]['activation']\n",
    "            batch_normalize = 'batch_normalize' in cfg_parser[section]\n",
    "\n",
    "            # padding='same' is equivalent to Darknet pad=1\n",
    "            padding = 'same' if pad == 1 else 'valid'\n",
    "\n",
    "            # Setting weights.\n",
    "            # Darknet serializes convolutional weights as:\n",
    "            # [bias/beta, [gamma, mean, variance], conv_weights]\n",
    "            prev_layer_shape = K.int_shape(prev_layer)\n",
    "\n",
    "            # TODO: This assumes channel last dim_ordering.\n",
    "            weights_shape = (size, size, prev_layer_shape[-1], filters)\n",
    "            darknet_w_shape = (filters, weights_shape[2], size, size)\n",
    "            weights_size = np.product(weights_shape)\n",
    "\n",
    "            print('conv2d', 'bn'\n",
    "                  if batch_normalize else '  ', activation, weights_shape)\n",
    "\n",
    "            conv_bias = np.ndarray(\n",
    "                shape=(filters, ),\n",
    "                dtype='float32',\n",
    "                buffer=weights_file.read(filters * 4))\n",
    "            count += filters\n",
    "\n",
    "            if batch_normalize:\n",
    "                bn_weights = np.ndarray(\n",
    "                    shape=(3, filters),\n",
    "                    dtype='float32',\n",
    "                    buffer=weights_file.read(filters * 12))\n",
    "                count += 3 * filters\n",
    "\n",
    "                # TODO: Keras BatchNormalization mistakenly refers to var\n",
    "                # as std.\n",
    "                bn_weight_list = [\n",
    "                    bn_weights[0],  # scale gamma\n",
    "                    conv_bias,  # shift beta\n",
    "                    bn_weights[1],  # running mean\n",
    "                    bn_weights[2]  # running var\n",
    "                ]\n",
    "\n",
    "            conv_weights = np.ndarray(\n",
    "                shape=darknet_w_shape,\n",
    "                dtype='float32',\n",
    "                buffer=weights_file.read(weights_size * 4))\n",
    "            count += weights_size\n",
    "\n",
    "            # DarkNet conv_weights are serialized Caffe-style:\n",
    "            # (out_dim, in_dim, height, width)\n",
    "            # We would like to set these to Tensorflow order:\n",
    "            # (height, width, in_dim, out_dim)\n",
    "            conv_weights = np.transpose(conv_weights, [2, 3, 1, 0])\n",
    "\n",
    "            conv_weights = [conv_weights] if batch_normalize else [\n",
    "                conv_weights, conv_bias\n",
    "            ]\n",
    "\n",
    "            # Handle activation.\n",
    "            act_fn = None\n",
    "            if activation == 'leaky':\n",
    "                pass  # Add advanced activation later.\n",
    "            elif activation != 'linear':\n",
    "                raise ValueError(\n",
    "                    'Unknown activation function `{}` in section {}'.format(\n",
    "                        activation, section))\n",
    "\n",
    "            # Create Conv2D layer\n",
    "            conv_layer = (Conv2D(\n",
    "                filters, (size, size),\n",
    "                strides=(stride, stride),\n",
    "                kernel_regularizer=l2(weight_decay),\n",
    "                use_bias=not batch_normalize,\n",
    "                weights=conv_weights,\n",
    "                activation=act_fn,\n",
    "                padding=padding))(prev_layer)\n",
    "\n",
    "            if batch_normalize:\n",
    "                conv_layer = (BatchNormalization(\n",
    "                    weights=bn_weight_list))(conv_layer)\n",
    "            prev_layer = conv_layer\n",
    "\n",
    "            if activation == 'linear':\n",
    "                all_layers.append(prev_layer)\n",
    "            elif activation == 'leaky':\n",
    "                act_layer = LeakyReLU(alpha=0.1)(prev_layer)\n",
    "                prev_layer = act_layer\n",
    "                all_layers.append(act_layer)\n",
    "\n",
    "        elif section.startswith('maxpool'):\n",
    "            size = int(cfg_parser[section]['size'])\n",
    "            stride = int(cfg_parser[section]['stride'])\n",
    "            all_layers.append(\n",
    "                MaxPooling2D(\n",
    "                    padding='same',\n",
    "                    pool_size=(size, size),\n",
    "                    strides=(stride, stride))(prev_layer))\n",
    "            prev_layer = all_layers[-1]\n",
    "\n",
    "        elif section.startswith('avgpool'):\n",
    "            if cfg_parser.items(section) != []:\n",
    "                raise ValueError('{} with params unsupported.'.format(section))\n",
    "            all_layers.append(GlobalAveragePooling2D()(prev_layer))\n",
    "            prev_layer = all_layers[-1]\n",
    "\n",
    "        elif section.startswith('route'):\n",
    "            ids = [int(i) for i in cfg_parser[section]['layers'].split(',')]\n",
    "            layers = [all_layers[i] for i in ids]\n",
    "            if len(layers) > 1:\n",
    "                print('Concatenating route layers:', layers)\n",
    "                concatenate_layer = concatenate(layers)\n",
    "                all_layers.append(concatenate_layer)\n",
    "                prev_layer = concatenate_layer\n",
    "            else:\n",
    "                skip_layer = layers[0]  # only one layer to route\n",
    "                all_layers.append(skip_layer)\n",
    "                prev_layer = skip_layer\n",
    "\n",
    "        elif section.startswith('upsample'):\n",
    "            stride = cfg_parser[section]['stride']\n",
    "            prev_layer = all_layers[-1]\n",
    "            all_layers.append(\n",
    "                UpSampling2D(size=(stride, stride), interpolation='nearest')(prev_layer)\n",
    "            )\n",
    "            prev_layer = all_layers[-1]\n",
    "            \n",
    "        elif section.startswith('shortcut'):\n",
    "            from_idx = cfg_parser[section]['from']\n",
    "\n",
    "            from_layer = all_layers[int(from_idx)]\n",
    "            prev_layer = all_layers[-1]\n",
    "\n",
    "            all_layers.append(\n",
    "                Add()([from_layer, prev_layer])\n",
    "            )\n",
    "            prev_layer = all_layers[-1]\n",
    "\n",
    "        elif section.startswith('yolo'):\n",
    "            prev_layer = all_layers[-1]\n",
    "            yolo_layer = Lambda(lambda x: x, name = f'yolo_{len(yolo_heads)}')(prev_layer)\n",
    "            all_layers.append(yolo_layer)\n",
    "            yolo_heads += [yolo_layer]\n",
    "            anchors = np.array(list(map(lambda x: int(x.strip()), cfg_parser[section]['anchors'].split(',')))).reshape((9, 2))\n",
    "            print(anchors)\n",
    "            prev_layer = all_layers[-1]\n",
    "\n",
    "\n",
    "        elif (section.startswith('net') or section.startswith('cost')\n",
    "              or section.startswith('softmax')):\n",
    "            pass  # Configs not currently handled during model definition.\n",
    "    \n",
    "        else:\n",
    "            raise ValueError(\n",
    "                'Unsupported section header type: {}'.format(section))\n",
    "\n",
    "    # Create and save model.\n",
    "    model = Model(inputs=all_layers[0], outputs=yolo_heads)\n",
    "    print(model.summary())\n",
    "    \n",
    "    remaining_weights = len(weights_file.read()) / 4\n",
    "    weights_file.close()\n",
    "    print(f'Warning: {remaining_weights} unused weights')\n",
    "\n",
    "\n",
    "    model.save(f'{output_path}')\n",
    "    print(f'Saved Keras model to {output_path}')\n",
    "    # Check to see if all weights have been read.\n",
    "    print(f'Read {count} of {count + remaining_weights} from Darknet weights.')\n",
    "\n",
    "    if plot_model:\n",
    "        if path_to_graph_output is None:\n",
    "            path_to_graph_output = output_root\n",
    "        plot(model, to_file=f'{path_to_graph_output}.png', show_shapes=True)\n",
    "        print(f'Saved model plot to {path_to_graph_output}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darknet_yolov2_to_keras(\n",
    "    YOLOV3_CFG_FILE_PATH,\n",
    "    YOLOV3_WEIGHTS_FILE_PATH,\n",
    "    './out/yolov3openimages_3heads_v3.h5', \n",
    "    fully_convolutional=True, \n",
    "    plot_model=True, \n",
    "    path_to_graph_output='./out/yolov3openimages_3heads_v3_graph'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import aiosqlite\n",
    "from data.openimages.constants import BoxableImagesConstants\n",
    "import asyncio\n",
    "import os\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from utils.np_array_db_converters import adapt_array, convert_array\n",
    "import PIL\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "import math\n",
    "from models.yolov3.utils import load_classes\n",
    "from utils.non_max_suppression import non_max_suppression\n",
    "\n",
    "# Converts numpy array to binary compressed version\n",
    "aiosqlite.register_adapter(np.ndarray, adapt_array)\n",
    "# Converts TEXT to np.array when selecting\n",
    "aiosqlite.register_converter(\"BLOB\", convert_array)\n",
    "\n",
    "SELECT_FIELDS_BOX = ['id', 'x_min', 'x_max', 'y_min', 'y_max', 'label_id', 'image_id']\n",
    "SELECT_FIELDS_IMAGE = ['id', 'image_bytes']\n",
    "\n",
    "OUT_GRID_WIDTH = 76\n",
    "OUT_GRID_HEIGHT = 76\n",
    "\n",
    "ANCHORS = np.array([\n",
    "    [[116,90],  [156,198],  [373,326]],\n",
    "    [[30,61],   [62,45],    [59,119]],\n",
    "    [[10,13],   [16,30],    [33,23]]\n",
    "])\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def parse_sql_result_to_object(sql_data_from_db, select_fields_arr):\n",
    "    obj = {}\n",
    "    for idx, value in enumerate(sql_data_from_db):\n",
    "        obj[select_fields_arr[idx]] = value\n",
    "        \n",
    "    return obj\n",
    "\n",
    "def drawrect(drawcontext, box_coords, color=\"red\", width=3):\n",
    "    x1, y1, x2, y2 = box_coords\n",
    "    offset = 1\n",
    "    for i in range(0, width):\n",
    "        drawcontext.rectangle(((x1, y1), (x2, y2)), outline=color)\n",
    "        x1 = x1 - offset\n",
    "        y1 = y1 + offset\n",
    "        x2 = x2 + offset\n",
    "        y2 = y2 - offset\n",
    "\n",
    "async def get_images_from_db(path_to_db, table_name_for_images, image_ids = [1]):\n",
    "    async with aiosqlite.connect(path_to_db, detect_types=sqlite3.PARSE_DECLTYPES) as db_conn:\n",
    "        cursor = await db_conn.cursor()\n",
    "        image_ids_placeholder = f'''({', '.join(['?' for _ in image_ids])})'''\n",
    "\n",
    "        await cursor.execute(f'''\n",
    "            SELECT {', '.join(SELECT_FIELDS_IMAGE)}\n",
    "            FROM {table_name_for_images}\n",
    "            WHERE id IN {image_ids_placeholder}\n",
    "        ''', image_ids)\n",
    "        \n",
    "        all_images = await cursor.fetchall()\n",
    "                    \n",
    "        return list(map(lambda sql_result: parse_sql_result_to_object(sql_result, SELECT_FIELDS_IMAGE), all_images))\n",
    "\n",
    "def draw_boxes(draw, img_bytes, predicted_reshaped, anchor_start_idx, class_idx_to_class_name):\n",
    "    box_candidates = []\n",
    "    box_scores = []\n",
    "    for col_idx, cell_grid in enumerate(predicted_reshaped[0]):\n",
    "        grid_width = predicted_reshaped.shape[1]\n",
    "        grid_height = predicted_reshaped.shape[2]\n",
    "\n",
    "        for row_idx, cell in enumerate(cell_grid):\n",
    "            for anchor_idx, box in enumerate(cell):\n",
    "                prob_obj = sigmoid(box[4])\n",
    "\n",
    "                class_probs = list(map(lambda x: sigmoid(x), box[5:]))\n",
    "                prob_chosen_class = prob_obj * np.array(class_probs)\n",
    "                \n",
    "                detected_classes_idx = np.where(prob_chosen_class > 0.3)[0]\n",
    "                \n",
    "                if len(detected_classes_idx) > 0:\n",
    "                    box_center_x_feat = sigmoid(box[0])\n",
    "                    box_center_y_feat = sigmoid(box[1])\n",
    "\n",
    "                    box_center_x = (row_idx + box_center_x_feat) / grid_width\n",
    "                    box_center_y = (col_idx + box_center_y_feat) / grid_height\n",
    "\n",
    "                    width_feat = box[2]\n",
    "                    height_feat = box[3]\n",
    "\n",
    "                    print(f'''img_bytes.shape={img_bytes.shape},\n",
    "                        ANCHORS[anchor_start_idx][anchor_idx][0]={ANCHORS[anchor_start_idx][anchor_idx][0]},\n",
    "                        ANCHORS[anchor_start_idx][anchor_idx][1]={ANCHORS[anchor_start_idx][anchor_idx][1]},\n",
    "                        np.exp(width_feat)={np.exp(width_feat)},\n",
    "                        np.exp(height_feat)={np.exp(height_feat)}\n",
    "                    anchor ''')\n",
    "\n",
    "                    grid_cell_width = np.exp(width_feat) * ANCHORS[anchor_start_idx][anchor_idx][0]\n",
    "                    grid_cell_height = np.exp(height_feat) * ANCHORS[anchor_start_idx][anchor_idx][1]\n",
    "\n",
    "                    box_center_x = box_center_x * img_bytes.shape[0]\n",
    "                    box_center_y = box_center_y * img_bytes.shape[1]\n",
    "\n",
    "                    width = grid_cell_width\n",
    "                    width_center = width / 2\n",
    "                    height = grid_cell_height\n",
    "                    height_center = height / 2\n",
    "\n",
    "                    box_candidates += [[\n",
    "                        box_center_x - width_center,\n",
    "                        box_center_y - height_center,\n",
    "                        box_center_x + width_center,\n",
    "                        box_center_y + height_center,\n",
    "                        detected_classes_idx\n",
    "                    ]]\n",
    "                    box_scores += [\n",
    "                        np.max(prob_chosen_class)\n",
    "                    ]\n",
    "                    \n",
    "    _, chosen_box_indices = non_max_suppression(box_candidates, box_scores, 0.6)\n",
    "    #     picked_boxes = non_max_suppression_fast(np.array(box_candidates))\n",
    "    \n",
    "    box_candidates = [box_candidates[i] for i in chosen_box_indices]\n",
    "    \n",
    "    for box in box_candidates:\n",
    "        x1, y1, x2, y2, detected_classes_indices = box\n",
    "        drawrect(draw, [x1, y1, x2, y2])\n",
    "        print(f'detected_classes_indices={detected_classes_indices}')\n",
    "        \n",
    "        detected_class_names = list(map(lambda idx: class_idx_to_class_name[idx], detected_classes_indices))\n",
    "        \n",
    "        \n",
    "        draw.text((((x1 + x2) // 2) - 5, ((y1+y2) //2 ) - 5), ','.join(detected_class_names), fill=\"red\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def draw_box(img, box):\n",
    "    print(box)\n",
    "    x_min_scaled = box['x_min'] * img.size[0]\n",
    "    x_max_scaled = box['x_max'] * img.size[0]\n",
    "\n",
    "    y_min_scaled = box['y_min'] * img.size[1]\n",
    "    y_max_scaled = box['y_max'] * img.size[1]\n",
    "\n",
    "    x_middle = (box['x_min'] + box['x_max']) / 2.\n",
    "    y_middle = (box['y_min'] + box['y_max']) / 2.\n",
    "\n",
    "    x_middle_scaled = x_middle  * img.size[0]\n",
    "    y_middle_scaled = y_middle  * img.size[1]\n",
    "\n",
    "\n",
    "    draw.line([(x_min_scaled, y_min_scaled), (x_max_scaled, y_min_scaled), (x_max_scaled, y_max_scaled), (x_min_scaled, y_max_scaled), (x_min_scaled, y_min_scaled)], fill = 128)\n",
    "\n",
    "    draw.point((x_middle_scaled, y_middle_scaled),  fill=(255,255,255,255))\n",
    "\n",
    "    draw.point((x_middle_scaled - 1, y_middle_scaled -1),  fill=(255,255,255,255))\n",
    "    draw.point((x_middle_scaled, y_middle_scaled -1),  fill=(255,255,255,255))\n",
    "    draw.point((x_middle_scaled + 1, y_middle_scaled -1),  fill=(255,255,255,255))\n",
    "\n",
    "    draw.point((x_middle_scaled + 1, y_middle_scaled -1),  fill=(255,255,255,255))\n",
    "    draw.point((x_middle_scaled + 1, y_middle_scaled),  fill=(255,255,255,255))\n",
    "    draw.point((x_middle_scaled + 1, y_middle_scaled +1),  fill=(255,255,255,255))\n",
    "\n",
    "async def test():\n",
    "    table_name_for_boxes = BoxableImagesConstants.TABLE_NAME_VAL_IMAGE_BOXES\n",
    "    table_name_for_images = BoxableImagesConstants.TABLE_NAME_VAL_BOXABLE_IMAGES\n",
    "    curr_path_to_db = os.path.join('..', 'db/boxable-images-608-608-subset-50.data')\n",
    "    \n",
    "    image_ids_to_test = [\n",
    "        1,2,3,4,5,6,7,8,9,10\n",
    "    ]\n",
    "    image_ids_to_test = [\n",
    "        30,31,32,33,34,35\n",
    "    ]\n",
    "\n",
    "\n",
    "    imgs_db = (await get_images_from_db(curr_path_to_db, table_name_for_images, image_ids_to_test))\n",
    "    # last one works :)\n",
    "    model_path = './out/yolov3openimages_3heads_v3.h5'\n",
    "    yolov3fully_conv = load_model(model_path, compile=False)\n",
    "    \n",
    "    class_idx_to_class_name = load_classes('../resources/yolov3/openimages.names')\n",
    "\n",
    "    \n",
    "    for img_db in imgs_db:\n",
    "        img = PIL.Image.fromarray(img_db['image_bytes'])\n",
    "\n",
    "        img_bytes = img_db['image_bytes']\n",
    "        arr = np.expand_dims(img_bytes, axis=0)\n",
    "\n",
    "\n",
    "        img = PIL.Image.fromarray(img_bytes)\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        predicted = yolov3fully_conv.predict(arr/255.)\n",
    "\n",
    "        for idx, yolo_predicted in enumerate(predicted):\n",
    "            np_arr_predicted = np.array(yolo_predicted)\n",
    "            np_arr_predicted = np_arr_predicted.reshape((1, np_arr_predicted.shape[1],np_arr_predicted.shape[2], 3, -1))\n",
    "            print(np_arr_predicted.shape)\n",
    "\n",
    "            draw_boxes(draw, img_bytes, np_arr_predicted, idx, class_idx_to_class_name)\n",
    "\n",
    "        img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_converted_model():\n",
    "    model_path_fully_convolutional = './yolov2_fully_convolutional.h5'\n",
    "    model_path = './yolov2_fully.h5'\n",
    "\n",
    "    yolov2fully_conv = load_model(model_path_fully_convolutional)\n",
    "    path_to_db = BoxableImagesConstants.PATH_TO_DB_YOLO_V2    \n",
    "    table_name_for_boxes = BoxableImagesConstants.TABLE_NAME_VAL_IMAGE_BOXES\n",
    "    table_name_for_images = BoxableImagesConstants.TABLE_NAME_VAL_BOXABLE_IMAGES\n",
    "    curr_path_to_db = os.path.join('..', path_to_db)\n",
    "\n",
    "    \n",
    "    img_db = (await get_images_from_db(curr_path_to_db, table_name_for_images, [14]))[0]\n",
    "    boxes_for_img = (await get_boxes_from_db(curr_path_to_db, table_name_for_boxes, [14]))[0]\n",
    "    \n",
    "    img_bytes = img_db['image_bytes']\n",
    "    \n",
    "    arr = np.expand_dims(img_bytes, axis = 0)\n",
    "    \n",
    "    print(arr.shape)\n",
    "    \n",
    "    predicted = np.array(yolov2fully_conv.predict(arr))\n",
    "    \n",
    "    print(predicted.shape)\n",
    "    \n",
    "    grid_width = img_bytes.shape[0] // 32\n",
    "    grid_height = img_bytes.shape[1] // 32\n",
    "    print(f'''\n",
    "        grid_width = {grid_width},\n",
    "        grid_height = {grid_height}\n",
    "    ''')\n",
    "    \n",
    "    predicted_reshaped = np.reshape(predicted, (1, 14, 14, 5, -1))\n",
    "    \n",
    "    img = PIL.Image.fromarray(img_bytes)\n",
    "    \n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    box_candidates = []\n",
    "    for col_idx, cell_grid in enumerate(predicted_reshaped[0]):\n",
    "#         print(f'cell_grid.shape: {cell_grid.shape}')\n",
    "        for row_idx, cell in enumerate(cell_grid):\n",
    "#             print(f'cell.shape: {cell.shape}')\n",
    "            for anchor_idx, box in enumerate(cell):\n",
    "                prob_obj = expit(box[4])\n",
    "                prob_class = expit(np.max(box[5:]))\n",
    "                class_idx = np.argmax(box[5:])\n",
    "                \n",
    "                prob_chosen_class = prob_obj * prob_class\n",
    "                if prob_chosen_class > 0.6:\n",
    "                    box_center_x_feat = expit(box[0])\n",
    "                    box_center_y_feat = expit(box[1])\n",
    "                    \n",
    "                    box_center_x = (row_idx + box_center_x_feat) / grid_width\n",
    "                    box_center_y = (col_idx + box_center_y_feat) / grid_height\n",
    "                    \n",
    "                    width_feat = box[2]\n",
    "                    height_feat = box[3]\n",
    "                    \n",
    "                    grid_cell_width = (np.exp(width_feat) * (ANCHORS[anchor_idx][0] / grid_width))\n",
    "                    grid_cell_height = (np.exp(height_feat) * (ANCHORS[anchor_idx][1] / grid_height))\n",
    "\n",
    "#                     width = (np.exp(width_feat) * ANCHORS[anchor_idx][0])\n",
    "#                     height = (np.exp(height_feat) * ANCHORS[anchor_idx][1])\n",
    "                    \n",
    "                    box_center_x = box_center_x * img_bytes.shape[0]\n",
    "                    box_center_y = box_center_y * img_bytes.shape[1]\n",
    "                                        \n",
    "                    width = grid_cell_width * (img_bytes.shape[0])\n",
    "                    width_center = width / 2\n",
    "                    height = grid_cell_height * (img_bytes.shape[1])\n",
    "                    height_center = height / 2\n",
    "                    \n",
    "                    box_candidates += [[\n",
    "                        box_center_x - width_center,\n",
    "                        box_center_y - height_center,\n",
    "                        box_center_x + width_center,\n",
    "                        box_center_y + height_center,\n",
    "                        class_idx\n",
    "                    ]]\n",
    "                    \n",
    "                    \n",
    "#                     print(f'box.shape: {box.shape}')\n",
    "#                     print(f'prob_obj = {prob_obj}')\n",
    "#                     print(f'''\n",
    "#                         box_center_x - width / 2 = {box_center_x - width / 2},\n",
    "#                         box_center_y - height / 2 = {box_center_y - height / 2},\n",
    "#                         box_center_x + width / 2 = {box_center_x + width / 2},\n",
    "#                         box_center_y + height / 2 = {box_center_y + height / 2},\n",
    "#                     ''')\n",
    "#                     print(f'''\n",
    "#                         prob_class = {prob_class}\n",
    "#                     ''')\n",
    "                    \n",
    "        \n",
    "    picked_boxes = non_max_suppression_fast(np.array(box_candidates))\n",
    "    \n",
    "    for box in picked_boxes:\n",
    "        x1, y1, x2, y2, class_idx = box\n",
    "#         draw_bounding_box(draw, x1, y1, x2, y2)\n",
    "        \n",
    "        drawrect(draw, [x1, y1, x2, y2])\n",
    "        draw.text((x1 + 5, y1 + 5), get_coco_class(class_idx), fill=\"red\")\n",
    "        print(f'class detected: {get_coco_class(class_idx)}')\n",
    "\n",
    "\n",
    "    print(predicted_reshaped.shape)\n",
    "    \n",
    "    img.show()\n",
    "\n",
    "    \n",
    "await test_converted_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
